# RL Snake CNN 训练优化设计

## 目标
- 将 `QNetwork` 改为轻量 CNN，适配大网格输入（50x50）。
- 在 50x50 场景下训练 2000 回合，提高策略质量与稳定性。

## 背景与问题
现有网络为全连接结构，对 50x50 的高维输入学习效率低、泛化差，训练数百回合后仍可能表现“直线走动、不追食物”。需要引入 CNN 提取空间特征，并延长训练回合数以提升策略质量。

## 方案概述
- **网络结构升级**：用 CNN 替换当前的纯线性网络，支持动态 `grid_size`。
- **训练回合数提升**：将 50x50 的 `train.episodes` 提升到 2000。
- **流程不变**：训练/评估/播放流程保持一致，仅替换网络结构与训练配置。

## 模型结构设计
建议网络结构（轻量、易训练）：
- `Conv2d(3→16, k=3, pad=1)` + `ReLU` + `MaxPool2d(2)`
- `Conv2d(16→32, k=3, pad=1)` + `ReLU` + `MaxPool2d(2)`
- `Flatten` + `Linear(in_features→128)` + `ReLU` + `Linear(128→num_actions)`

其中 `in_features` 通过 **假输入** 动态计算，保证对不同 `grid_size`（如 5、10、50）都能工作。

## 训练配置建议
在保持其它配置不变的情况下：
- `train.episodes = 2000`
- `grid_size = 50`

如需更平滑探索，可将 `epsilon_decay` 稍调慢（如 0.995），但此项可选。

## 数据流与兼容性
- `train_dqn` 仍以 `QNetwork` 为入口，换 CNN 后输出维度不变。
- `play` 仍通过 `checkpoint` 加载模型；**注意** 新模型与旧模型不兼容（输入维度不同）。

## 测试策略
新增网络测试，确保：
- `QNetwork` 内包含 `Conv2d`
- 对输入 `(3, 5, 5)` 时输出维度为 `num_actions`
- 旧训练/播放测试保持通过

## 风险与对策
- **训练耗时**：2000 回合会明显更久，建议分阶段观察曲线。
- **策略仍不理想**：如效果仍弱，考虑增加回合数或更深网络，但先以轻量 CNN 为主。
